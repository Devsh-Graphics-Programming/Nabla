#version 430 core
#include "raytraceCommon.glsl"

// for per pixel inputs
#include <nbl/builtin/glsl/utils/normal_decode.glsl>
#include <nbl/builtin/glsl/random/xoroshiro.glsl>
#include <nbl/builtin/glsl/utils/transform.glsl>

// rng
layout(set = 3, binding = 0) uniform usamplerBuffer sampleSequence;
layout(set = 3, binding = 1) uniform usampler2D scramblebuf;
// vis buffer
layout(set = 3, binding = 2) uniform sampler2D depthbuf;
layout(set = 3, binding = 3) uniform usampler2D frontFacing_Object_Triangle;
layout(set = 3, binding = 4) uniform sampler2D encodedNormal;
layout(set = 3, binding = 5) uniform sampler2D uvCoords;
//layout(set = 2, binding = 6) uniform sampler2D barycentricDerivatives; // in the future we shall compute them from triangle vertex positions


#include "bin/material_declarations.glsl"
#include <nbl/builtin/glsl/ext/MitsubaLoader/material_compiler_compatibility_impl.glsl>
vec3 normalizedV;
vec3 nbl_glsl_MC_getNormalizedWorldSpaceV()
{
	return normalizedV;
}
vec3 normalizedN;
vec3 nbl_glsl_MC_getNormalizedWorldSpaceN()
{
	return normalizedN;
}
mat2x3 dPdBary;
mat2x3 nbl_glsl_perturbNormal_dPdSomething()
{
	return dPdBary;
}
mat2 dUVdBary;
mat2 nbl_glsl_perturbNormal_dUVdSomething()
{
    return dUVdBary;
}
#define _NBL_USER_PROVIDED_MATERIAL_COMPILER_GLSL_BACKEND_FUNCTIONS_
#include <nbl/builtin/glsl/material_compiler/common.glsl>


/*
float maxAbs1(in float val) 
{
	return abs(val);
}
float maxAbs2(in vec2 val)
{
	vec2 v = abs(val);
	return max(v.x,v.y);
}
float maxAbs3(in vec3 val)
{
	vec3 v = abs(val);
	return max(max(v.x,v.y),v.z);
}

float GET_MAGNITUDE(in float val)
{
	float x = abs(val);
	return uintBitsToFloat(floatBitsToUint(x)&2139095040u);
}

float ULP1(in float val, in uint accuracy)
{
	float x = abs(val);
	return uintBitsToFloat(floatBitsToUint(x) + accuracy)-x;
}
float ULP2(in vec2 val, in uint accuracy)
{
	float x = maxAbs2(val);
	return uintBitsToFloat(floatBitsToUint(x) + accuracy)-x;
}
float ULP3(in vec3 val, in uint accuracy)
{
	float x = maxAbs3(val);
	return uintBitsToFloat(floatBitsToUint(x) + accuracy)-x;
}
*/

vec3 rand3d(inout nbl_glsl_xoroshiro64star_state_t scramble_state, in uint _sample)
{
	uvec3 seqVal = texelFetch(sampleSequence,int(_sample)).xyz;
	seqVal ^= uvec3(nbl_glsl_xoroshiro64star(scramble_state),nbl_glsl_xoroshiro64star(scramble_state),nbl_glsl_xoroshiro64star(scramble_state));
    return vec3(seqVal)*uintBitsToFloat(0x2f800004u);
}

void gen_sample_ray(
	out float maxT, out vec3 direction, out vec3 throughput,
	inout nbl_glsl_xoroshiro64star_state_t scramble_state, in uint sampleID,
	in nbl_glsl_MC_precomputed_t precomp, in nbl_glsl_MC_instr_stream_t gcs, in nbl_glsl_MC_instr_stream_t rnps
)
{
	maxT = FLT_MAX;
	
	vec3 rand = rand3d(scramble_state,sampleID);
	
	float pdf;
	nbl_glsl_LightSample s;
	throughput = nbl_glsl_MC_runGenerateAndRemainderStream(precomp, gcs, rnps, rand, pdf, s);
	throughput /= float(staticViewData.samplesPerPixelPerDispatch);

	direction = s.L;
}

void main()
{
	uvec2 outputLocation = gl_GlobalInvocationID.xy;
	if (all(lessThan(outputLocation,staticViewData.imageDimensions)))
	{
		ivec2 pixelCoord = ivec2(outputLocation);
		float revdepth = texelFetch(depthbuf,pixelCoord,0).r;

		const uint outputID = outputLocation.y*staticViewData.samplesPerRowPerDispatch+outputLocation.x*staticViewData.samplesPerPixelPerDispatch;
		
		nbl_glsl_xoroshiro64star_state_t scramble_start_state; // this should get advanced for secondary rays by 3 or 4 iterations
		
		vec3 worldPosition;
		nbl_glsl_MC_instr_stream_t gcs;
		nbl_glsl_MC_instr_stream_t rnps;
		nbl_glsl_MC_precomputed_t precomputed;

		const bool nonBackgroudPixel = revdepth>0.0;
		vec3 emissive = staticViewData.envmapBaseColor;
		if (nonBackgroudPixel)
		{			
			// vis buffer read
			const uvec2 visBuffer = texelFetch(frontFacing_Object_Triangle,pixelCoord,0).rg;
			// init scramble
			scramble_start_state = texelFetch(scramblebuf,pixelCoord,0).rg;
			// vertex attribute reads
			vec3 positions[3];
			vec2 uvs[3];
#if 0
            dPdBary[0] = positions[0]-positions[2];
            dPdBary[1] = positions[1]-positions[2];
            dUVdBary[0] = uvs[0]-uvs[2];
            dUVdBary[1] = uvs[1]-uvs[2];
            const vec2 UV = dUVdBary*bary+uvs[2];
			const vec3 normal = ;
#endif
			// tmp gbuffer reads
			const vec2 normalBuffer = texelFetch(encodedNormal,pixelCoord,0).rg;
			const vec2 UV = texelFetch(uvCoords,pixelCoord,0).xy;
			mat2 dBarydScreen = mat2(0.0); // TODO:
			mat2 dUVdBary = mat2(0.0); // TODO:
			mat2 dUVdScreen = nbl_glsl_applyChainRule2D(dUVdBary,dBarydScreen);
			
			// unproject
			{
				const vec3 NDC = vec3(vec2(outputLocation)*staticViewData.rcpPixelSize+staticViewData.rcpHalfPixelSize,1.0-revdepth);
				
				vec4 tmp = nbl_glsl_pseudoMul4x4with3x1(pc.cummon.inverseMVP,NDC);
				worldPosition = tmp.xyz/tmp.w;

				const vec3 V = nbl_glsl_pseudoMul3x4with3x1(pc.cummon.ndcToV,NDC);
				normalizedV = normalize(V);
			}
			
			// decode vis buffer
			{
				const uint objectID = visBuffer[0]&0x7fffffffu;
				const uint triangleID = visBuffer[1];
				const bool frontfacing = objectID==visBuffer[0];

				nbl_glsl_MC_oriented_material_t material = nbl_glsl_MC_material_data_t_getOriented(InstData.data[objectID].material,frontfacing);
				
				// use loaded data
				emissive = nbl_glsl_MC_oriented_material_t_getEmissive(material);
				gcs = nbl_glsl_MC_oriented_material_t_getGenChoiceStream(material);
				rnps = nbl_glsl_MC_oriented_material_t_getRemAndPdfStream(material);
				
				// normally we'd use MeshPackerV2's vertex attribute data for this, but now we read from temporary GBuffer
				const vec3 normal = nbl_glsl_NormalDecode_signedSpherical(normalBuffer);
				normalizedN.x = dot(InstData.data[objectID].normalMatrixRow0,normal);
				normalizedN.y = dot(InstData.data[objectID].normalMatrixRow1,normal);
				normalizedN.z = dot(InstData.data[objectID].normalMatrixRow2,normal);
				
				// need to do this after we have world, V and N ready
				precomputed = nbl_glsl_MC_precomputeData(frontfacing);

				// prefetch textures and normals
				#ifdef TEX_PREFETCH_STREAM
					nbl_glsl_MC_runTexPrefetchStream(nbl_glsl_MC_oriented_material_t_getTexPrefetchStream(material), UV, dUVdScreen);
				#endif
				#ifdef NORM_PRECOMP_STREAM
					nbl_glsl_MC_runNormalPrecompStream(nbl_glsl_MC_oriented_material_t_getNormalPrecompStream(material), precomputed);
				#endif
			}
		}
			
		//
		if (any(greaterThan(emissive,vec3(FLT_MIN))))
		{
			vec3 acc = emissive;
			if (pc.cummon.rcpFramesDispatched<1.0)
			{
				acc /= float(pc.cummon.framesDispatched-1u);
				acc += fetchAccumulation(pixelCoord);
			}
			storeAccumulation(acc,pixelCoord);
		}
#ifdef USE_OPTIX_DENOISER
		// TODO: translate normal into float16_t buff
#endif

		for (uint i=0u; i<staticViewData.samplesPerPixelPerDispatch; i++)
		{
			vec3 direction;
			float maxT;
			vec4 throughput = vec4(0.0,0.0,0.0,-1.0); // -1 needs to be there to ensure no backface culling on rays

			if (nonBackgroudPixel)
			{
				nbl_glsl_xoroshiro64star_state_t scramble_state = scramble_start_state;
				const uint sampleID = pc.cummon.samplesComputedPerPixel+i;
				gen_sample_ray(maxT,direction,throughput.rgb,scramble_state,sampleID,precomputed,gcs,rnps);
			}
			
			// TODO: repack rays in smem for coalescing, or optimize this somehow
			const uint realOutputID = outputID+i;
			const bool validRay = any(greaterThan(throughput.rgb,vec3(FLT_MIN)));
			if (validRay)
			{
				const float err = 1.0/64.0; // TODO: improve ray offsets
				rays[realOutputID].origin = worldPosition+direction*err;
				rays[realOutputID].maxT = max(maxT-err,0.0);
				rays[realOutputID].direction = direction;
				rays[realOutputID].mask = -1;
				rays[realOutputID]._active = 1;
			}
			else
			{
				rays[realOutputID].maxT = 0.0;
				rays[realOutputID].mask = 0;
				rays[realOutputID]._active = 0;
			}
			rays[realOutputID].backfaceCulling = int(packHalf2x16(throughput.ab));
			rays[realOutputID].useless_padding = int(packHalf2x16(throughput.gr));
		}
	}
}