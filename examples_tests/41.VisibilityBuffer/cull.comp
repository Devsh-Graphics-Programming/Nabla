#version 430 core
#extension GL_EXT_shader_16bit_storage : require

#include "rasterizationCommon.h"
layout(local_size_x = WORKGROUP_SIZE) in;

layout(set=0, binding=0, std430, row_major) restrict readonly buffer PerInstanceCull
{
    CullData_t cullData[];
};
layout(set=0, binding=1, std430) restrict buffer MVPs
{
    mat4 mvps[];
} mvpBuff;

layout(set=0, binding=2, std430, column_major) restrict buffer CubeMVPs
{
    mat4 cubeMVPs[];
} cubeMvpBuff;

#define CUBE_COMMAND_BUFF_SET 0
#define CUBE_COMMAND_BUFF_BINDING 3
#define FRUSTUM_CULLED_COMMAND_BUFF_SET 0
#define FRUSTUM_CULLED_COMMAND_BUFF_BINDING 4
#define OCCLUSION_CULLED_COMMAND_BUFF_SET 0
#define OCCLUSION_CULLED_COMMAND_BUFF_BINDING 5
#define CUBE_DRAW_GUID_BUFF_SET 0
#define CUBE_DRAW_GUID_BUFF_BINDING 6
#define OCCLUSION_DISPATCH_INDIRECT_BUFF_SET 0
#define OCCLUSION_DISPATCH_INDIRECT_BUFF_BINDING 7
#define VISIBLE_BUFF_SET 0
#define VISIBLE_BUFF_BINDING 8
#include "occlusionCullingShaderCommon.glsl"

layout(push_constant, row_major) uniform PushConstants
{
    CullShaderData_t data;
} pc;

#include <nbl/builtin/glsl/utils/culling.glsl>
#include <nbl/builtin/glsl/utils/transform.glsl>

bool unpackFreezeCullFlag(in uint packedVal)
{
    return bool(packedVal >> 16u);
}

uint unpackMaxBatchCount(in uint packedVal)
{
    return packedVal & 0x0000FFFFu;
}

void main()
{
    if (gl_GlobalInvocationID.x >= unpackMaxBatchCount(pc.data.freezeCullingAndMaxBatchCountPacked))
        return;
    
    mvpBuff.mvps[gl_GlobalInvocationID.x] = pc.data.viewProjMatrix; // no model matrices

    const CullData_t batchCullData = cullData[gl_GlobalInvocationID.x];
    const uint drawCommandGUID = batchCullData.drawCommandGUID;
    occlusionCommandBuff.draws[drawCommandGUID].instanceCount = 0;

    if (unpackFreezeCullFlag(pc.data.freezeCullingAndMaxBatchCountPacked))
        return;


    const mat2x3 bbox = mat2x3(batchCullData.aabbMinEdge,batchCullData.aabbMaxEdge);
    bool couldBeVisible = nbl_glsl_couldBeVisible(pc.data.viewProjMatrix,bbox);
    
    if (couldBeVisible)
    {
        const vec3 localCameraPos = pc.data.worldCamPos; // true in this case
        const bool cameraInsideAABB = all(greaterThanEqual(localCameraPos, batchCullData.aabbMinEdge)) && all(lessThanEqual(localCameraPos, batchCullData.aabbMaxEdge));
        const bool assumedVisible = uint(visibleBuff.visible[gl_GlobalInvocationID.x]) == 1u || cameraInsideAABB;
        frustumCommandBuff.draws[drawCommandGUID].instanceCount = assumedVisible ? 1u : 0u;
        // if not frustum culled and batch was not visible in the last frame, and it makes sense to test
        if(!assumedVisible)
        {
            const uint currCubeIdx = atomicAdd(cubeIndirectDraw.draw.instanceCount, 1);

            if(currCubeIdx % WORKGROUP_SIZE == 0)
                atomicAdd(occlusionDispatchIndirect.di.num_groups_x, 1);

            // only works for a source geometry box which is [0,1]^2, the geometry creator box is [-0.5,0.5]^2, so either make your own box, or work out the math for this
            vec3 aabbExtent = batchCullData.aabbMaxEdge - batchCullData.aabbMinEdge;
            cubeMvpBuff.cubeMVPs[currCubeIdx] = mat4(
                pc.data.viewProjMatrix[0]*aabbExtent.x,
                pc.data.viewProjMatrix[1]*aabbExtent.y,
                pc.data.viewProjMatrix[2]*aabbExtent.z,
                pc.data.viewProjMatrix*vec4(batchCullData.aabbMinEdge,1)
            );

            cubeDrawGUIDBuffer.drawGUID[currCubeIdx] = drawCommandGUID;
        }
    }
    else
        frustumCommandBuff.draws[drawCommandGUID].instanceCount = 0;

    // does `freezeCulling` affect this negatively?
    visibleBuff.visible[gl_GlobalInvocationID.x] = uint16_t(0u);
}